{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ef0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing activity labels...\n",
      "Loading and parsing activity labels...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "# Step 1: Load and Parse Activity Labels\n",
    "print(\"Loading and parsing activity labels...\")\n",
    "# Step 1: Load and Parse Activity Labels\n",
    "print(\"Loading and parsing activity labels...\")\n",
    "activities_df = pd.read_csv(r'C:\\projs\\tmc\\TrainingDataPD25\\TrainingDataPD25\\TrainActivities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298fc66",
   "metadata": {},
   "source": [
    "### dateTime-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c818f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started     datetime64[ns]\n",
      "Finished    datetime64[ns]\n",
      "Updated     datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Activity Type ID</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Started</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1130251</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>U22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1130254</td>\n",
       "      <td>2807</td>\n",
       "      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>U22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130257</td>\n",
       "      <td>2807</td>\n",
       "      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>U22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1130261</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>U22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1130292</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>U2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Activity Type ID  \\\n",
       "0  1130251              2806   \n",
       "1  1130254              2807   \n",
       "2  1130257              2807   \n",
       "3  1130261              2806   \n",
       "4  1130292              2806   \n",
       "\n",
       "                                       Activity Type             Started  \\\n",
       "0                    1 (FACING camera) Sit and stand 2024-09-02 06:16:00   \n",
       "1  2 (FACING camera) both hands SHAKING (sitting ... 2024-09-02 06:17:00   \n",
       "2  2 (FACING camera) both hands SHAKING (sitting ... 2024-09-02 06:18:00   \n",
       "3                    1 (FACING camera) Sit and stand 2024-09-02 06:20:00   \n",
       "4                    1 (FACING camera) Sit and stand 2024-09-02 06:42:00   \n",
       "\n",
       "             Finished             Updated Subject  \n",
       "0 2024-09-02 06:16:00 2024-09-02 06:16:00     U22  \n",
       "1 2024-09-02 06:17:00 2024-09-02 06:17:00     U22  \n",
       "2 2024-09-02 06:18:00 2024-09-02 06:18:00     U22  \n",
       "3 2024-09-02 06:20:00 2024-09-02 06:20:00     U22  \n",
       "4 2024-09-02 06:42:00 2024-09-02 06:42:00      U2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_columns = ['Started', 'Finished', 'Updated']\n",
    "\n",
    "# Convert while keeping NaNs intact\n",
    "activities_df[date_columns] = activities_df[date_columns].apply(\n",
    "    pd.to_datetime, format='%Y/%m/%d %H:%M', errors='coerce'\n",
    ")\n",
    "\n",
    "# Check result\n",
    "print(activities_df[date_columns].dtypes)\n",
    "activities_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668e3ef",
   "metadata": {},
   "source": [
    "### Checking for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ace270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN/NaT counts per column:\n",
      "ID                   0\n",
      "Activity Type ID     0\n",
      "Activity Type        0\n",
      "Started             66\n",
      "Finished            67\n",
      "Updated              0\n",
      "Subject              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List the columns you want to check\n",
    "columns_to_check = activities_df.columns  # change this list as needed\n",
    "\n",
    "# Check for NaN/NaT counts in each of the specified columns\n",
    "nan_counts = activities_df[columns_to_check].isna().sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"NaN/NaT counts per column:\")\n",
    "print(nan_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f9f1d",
   "metadata": {},
   "source": [
    "### Making activity classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17a4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 342 activities for subjects: ['U22' 'U2' 'U1' 'U21' 'U4' 'U5' 'U3' 'U6' 'U7']\n"
     ]
    }
   ],
   "source": [
    "activities_df['activity_class'] = activities_df['Activity Type'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "print(f\"Loaded {len(activities_df)} activities for subjects: {activities_df['Subject'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57fdd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3530 sensor data files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "sensor_files = glob.glob(r'C:/projs/tmc/TrainingDataPD25/TrainingDataPD25/users_timeXYZ/users/*/*.csv', recursive=True)\n",
    "print(f\"Found {len(sensor_files)} sensor data files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a4697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_24460\\1245783144.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(file, header=None, parse_dates=[1])\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_24460\\1245783144.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(file, header=None, parse_dates=[1])\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_24460\\1245783144.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(file, header=None, parse_dates=[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created metadata for 3530 sensor files across 18 subdirectories.\n"
     ]
    }
   ],
   "source": [
    "# Create metadata for sensor files (min/max timestamps)\n",
    "metadata = []\n",
    "for file in sensor_files:\n",
    "    # Load only the timestamp column (index 1)\n",
    "    df = pd.read_csv(file, header=None, parse_dates=[1])\n",
    "    min_time = df[1].min()\n",
    "    max_time = df[1].max()\n",
    "    subdir = os.path.basename(os.path.dirname(file))\n",
    "    metadata.append({'file': file, 'subdir': subdir, 'min_time': min_time, 'max_time': max_time})\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "print(f\"Created metadata for {len(metadata_df)} sensor files across {metadata_df['subdir'].nunique()} subdirectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc806bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Activity Type ID</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Started</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Subject</th>\n",
       "      <th>activity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1130251</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>2024-09-02 06:16:00</td>\n",
       "      <td>U22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1130254</td>\n",
       "      <td>2807</td>\n",
       "      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>2024-09-02 06:17:00</td>\n",
       "      <td>U22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130257</td>\n",
       "      <td>2807</td>\n",
       "      <td>2 (FACING camera) both hands SHAKING (sitting ...</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>2024-09-02 06:18:00</td>\n",
       "      <td>U22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1130261</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>2024-09-02 06:20:00</td>\n",
       "      <td>U22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1130292</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>2024-09-02 06:42:00</td>\n",
       "      <td>U2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1164181</td>\n",
       "      <td>2815</td>\n",
       "      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-09-11 04:55:00</td>\n",
       "      <td>U7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1164187</td>\n",
       "      <td>2806</td>\n",
       "      <td>1 (FACING camera) Sit and stand</td>\n",
       "      <td>2024-09-11 04:58:00</td>\n",
       "      <td>2024-09-11 04:58:00</td>\n",
       "      <td>2024-09-11 04:58:00</td>\n",
       "      <td>U7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1164217</td>\n",
       "      <td>2815</td>\n",
       "      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n",
       "      <td>2024-09-11 05:09:00</td>\n",
       "      <td>2024-09-11 05:10:00</td>\n",
       "      <td>2024-09-11 05:10:00</td>\n",
       "      <td>U7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1164218</td>\n",
       "      <td>2815</td>\n",
       "      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n",
       "      <td>2024-09-11 05:10:00</td>\n",
       "      <td>2024-09-11 05:10:00</td>\n",
       "      <td>2024-09-11 05:10:00</td>\n",
       "      <td>U7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1164219</td>\n",
       "      <td>2815</td>\n",
       "      <td>10 Slow walk (SHAKING hands/body, tiny step, h...</td>\n",
       "      <td>2024-09-11 05:11:00</td>\n",
       "      <td>2024-09-11 05:11:00</td>\n",
       "      <td>2024-09-11 05:11:00</td>\n",
       "      <td>U7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Activity Type ID  \\\n",
       "0    1130251              2806   \n",
       "1    1130254              2807   \n",
       "2    1130257              2807   \n",
       "3    1130261              2806   \n",
       "4    1130292              2806   \n",
       "..       ...               ...   \n",
       "337  1164181              2815   \n",
       "338  1164187              2806   \n",
       "339  1164217              2815   \n",
       "340  1164218              2815   \n",
       "341  1164219              2815   \n",
       "\n",
       "                                         Activity Type             Started  \\\n",
       "0                      1 (FACING camera) Sit and stand 2024-09-02 06:16:00   \n",
       "1    2 (FACING camera) both hands SHAKING (sitting ... 2024-09-02 06:17:00   \n",
       "2    2 (FACING camera) both hands SHAKING (sitting ... 2024-09-02 06:18:00   \n",
       "3                      1 (FACING camera) Sit and stand 2024-09-02 06:20:00   \n",
       "4                      1 (FACING camera) Sit and stand 2024-09-02 06:42:00   \n",
       "..                                                 ...                 ...   \n",
       "337  10 Slow walk (SHAKING hands/body, tiny step, h...                 NaT   \n",
       "338                    1 (FACING camera) Sit and stand 2024-09-11 04:58:00   \n",
       "339  10 Slow walk (SHAKING hands/body, tiny step, h... 2024-09-11 05:09:00   \n",
       "340  10 Slow walk (SHAKING hands/body, tiny step, h... 2024-09-11 05:10:00   \n",
       "341  10 Slow walk (SHAKING hands/body, tiny step, h... 2024-09-11 05:11:00   \n",
       "\n",
       "               Finished             Updated Subject  activity_class  \n",
       "0   2024-09-02 06:16:00 2024-09-02 06:16:00     U22               1  \n",
       "1   2024-09-02 06:17:00 2024-09-02 06:17:00     U22               2  \n",
       "2   2024-09-02 06:18:00 2024-09-02 06:18:00     U22               2  \n",
       "3   2024-09-02 06:20:00 2024-09-02 06:20:00     U22               1  \n",
       "4   2024-09-02 06:42:00 2024-09-02 06:42:00      U2               1  \n",
       "..                  ...                 ...     ...             ...  \n",
       "337                 NaT 2024-09-11 04:55:00      U7              10  \n",
       "338 2024-09-11 04:58:00 2024-09-11 04:58:00      U7               1  \n",
       "339 2024-09-11 05:10:00 2024-09-11 05:10:00      U7              10  \n",
       "340 2024-09-11 05:10:00 2024-09-11 05:10:00      U7              10  \n",
       "341 2024-09-11 05:11:00 2024-09-11 05:11:00      U7              10  \n",
       "\n",
       "[342 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33dcbce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns] and Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimelike.py:536\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimes.py:540\u001b[39m, in \u001b[36mDatetimeArray._check_compatible_with\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assert_tzawareness_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimes.py:782\u001b[39m, in \u001b[36mDatetimeArray._assert_tzawareness_compat\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    781\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    783\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot compare tz-naive and tz-aware datetime-like objects.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    784\u001b[39m         )\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Cannot compare tz-naive and tz-aware datetime-like objects.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInvalidComparison\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimelike.py:983\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     other = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_comparison_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimelike.py:539\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    538\u001b[39m         \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidComparison(other) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(other):\n",
      "\u001b[31mInvalidComparison\u001b[39m: 2024-09-05 09:30:25.586000+01:00",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m subdir_min = row[\u001b[33m'\u001b[39m\u001b[33mmin_time\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m subdir_max = row[\u001b[33m'\u001b[39m\u001b[33mmax_time\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m overlapping_subjects = subject_times[\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     (\u001b[43msubject_times\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStarted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msubdir_max\u001b[49m) & \n\u001b[32m     10\u001b[39m     (subject_times[\u001b[33m'\u001b[39m\u001b[33mFinished\u001b[39m\u001b[33m'\u001b[39m] >= subdir_min)\n\u001b[32m     11\u001b[39m ].index\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(overlapping_subjects) == \u001b[32m1\u001b[39m:\n\u001b[32m     13\u001b[39m     subdir_to_subject[subdir] = overlapping_subjects[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:6119\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:330\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mLengths must match to compare\u001b[39m\u001b[33m\"\u001b[39m, lvalues.shape, rvalues.shape\n\u001b[32m    323\u001b[39m         )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    326\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[32m    327\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m lvalues.dtype != \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    328\u001b[39m ):\n\u001b[32m    329\u001b[39m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     res_values = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator.ne:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimelike.py:985\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m    983\u001b[39m     other = \u001b[38;5;28mself\u001b[39m._validate_comparison_value(other)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvalid_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m dtype = \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype):\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# We have to use comp_method_OBJECT_ARRAY instead of numpy\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m#  comparison otherwise it would raise when comparing to None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\invalid.py:40\u001b[39m, in \u001b[36minvalid_comparison\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m     typ = \u001b[38;5;28mtype\u001b[39m(right).\u001b[34m__name__\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid comparison between dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[31mTypeError\u001b[39m: Invalid comparison between dtype=datetime64[ns] and Timestamp"
     ]
    }
   ],
   "source": [
    "subject_times = activities_df.groupby('Subject').agg({'Started': 'min', 'Finished': 'max'})\n",
    "subdir_times = metadata_df.groupby('subdir').agg({'min_time': 'min', 'max_time': 'max'})\n",
    "\n",
    "subdir_to_subject = {}\n",
    "for subdir, row in subdir_times.iterrows():\n",
    "    subdir_min = row['min_time']\n",
    "    subdir_max = row['max_time']\n",
    "    overlapping_subjects = subject_times[\n",
    "        (subject_times['Started'] <= subdir_max) & \n",
    "        (subject_times['Finished'] >= subdir_min)\n",
    "    ].index\n",
    "    if len(overlapping_subjects) == 1:\n",
    "        subdir_to_subject[subdir] = overlapping_subjects[0]\n",
    "    else:\n",
    "        print(f\"Warning: Ambiguity for subdir {subdir} with subjects {overlapping_subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Root directory where the Activity Type ID folders are stored\n",
    "root_dir = r'C:\\projs\\tmc\\TrainingDataPD25\\TrainingDataPD25\\users_timeXYZ\\users'\n",
    "\n",
    "# List to hold all dataframes\n",
    "all_csv_data = []\n",
    "\n",
    "# Loop through each folder in the root directory\n",
    "for activity_folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, activity_folder)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        # Find all CSV files inside the activity folder\n",
    "        csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "        \n",
    "        for file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                df['Activity_Type_ID'] = activity_folder  # Tag with folder name\n",
    "                df['Source_File'] = os.path.basename(file)  # Optionally track file name\n",
    "                all_csv_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {file}: {e}\")\n",
    "\n",
    "# Combine all into a single DataFrame\n",
    "combined_df = pd.concat(all_csv_data, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd10bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Subdirectory 1716 matches 0 subjects.\n",
      "Warning: Subdirectory 2803 matches 2 subjects.\n",
      "Warning: Subdirectory 2804 matches 6 subjects.\n",
      "Warning: Subdirectory 2805 matches 6 subjects.\n",
      "Warning: Subdirectory 2806 matches 3 subjects.\n",
      "Warning: Subdirectory 2807 matches 3 subjects.\n",
      "Warning: Subdirectory 2808 matches 0 subjects.\n",
      "Warning: Subdirectory 2809 matches 0 subjects.\n",
      "Warning: Subdirectory 2810 matches 0 subjects.\n",
      "Warning: Subdirectory 2811 matches 0 subjects.\n",
      "Warning: Subdirectory 2813 matches 0 subjects.\n",
      "Warning: Subdirectory 2814 matches 0 subjects.\n",
      "Warning: Subdirectory 2815 matches 3 subjects.\n",
      "Warning: Subdirectory 2816 matches 0 subjects.\n",
      "Warning: Subdirectory 2819 matches 0 subjects.\n",
      "Warning: Subdirectory 2830 matches 7 subjects.\n",
      "Warning: Subdirectory 38 matches 0 subjects.\n",
      "Mapped 1 subdirectories to subjects.\n",
      "Processed data for subject U7 from subdirectory 2812.\n",
      "Total labeled data points: 0\n"
     ]
    }
   ],
   "source": [
    "def get_time_range(subdir):\n",
    "    \"\"\"Get the min and max timestamps from all CSV files in a subdirectory.\"\"\"\n",
    "    csv_files = [f for f in os.listdir(os.path.join(data_dir, subdir)) if f.endswith('.csv')]\n",
    "    \n",
    "    min_ts, max_ts = None, None\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(data_dir, subdir, csv_file)\n",
    "        df = pd.read_csv(file_path, usecols=[1], header=None)\n",
    "        df.columns = ['Timestamp']\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', dayfirst=True)\n",
    "\n",
    "        # Convert to UTC\n",
    "        df['Timestamp'] = df['Timestamp'].dt.tz_localize('UTC') if df['Timestamp'].dt.tz is None else df['Timestamp'].dt.tz_convert('UTC')\n",
    "\n",
    "        current_min = df['Timestamp'].min()\n",
    "        current_max = df['Timestamp'].max()\n",
    "        min_ts = current_min if min_ts is None or current_min < min_ts else min_ts\n",
    "        max_ts = current_max if max_ts is None or current_max > max_ts else max_ts\n",
    "    return min_ts, max_ts\n",
    "\n",
    "# Compute time ranges for each subdirectory\n",
    "subdir_time_ranges = {subdir: get_time_range(subdir) for subdir in subdirs}\n",
    "\n",
    "def intervals_overlap(subdir_min, subdir_max, intervals):\n",
    "    \"\"\"Check if subdirectory time range overlaps with any activity interval.\"\"\"\n",
    "    \n",
    "    # Localize subdir timestamps if needed\n",
    "    if subdir_min.tzinfo is None:\n",
    "        subdir_min = subdir_min.tz_localize('UTC')\n",
    "    else:\n",
    "        subdir_min = subdir_min.tz_convert('UTC')\n",
    "\n",
    "    if subdir_max.tzinfo is None:\n",
    "        subdir_max = subdir_max.tz_localize('UTC')\n",
    "    else:\n",
    "        subdir_max = subdir_max.tz_convert('UTC')\n",
    "\n",
    "    for start, end in intervals:\n",
    "        # Localize each interval if needed\n",
    "        if start.tzinfo is None:\n",
    "            start = start.tz_localize('UTC')\n",
    "        else:\n",
    "            start = start.tz_convert('UTC')\n",
    "\n",
    "        if end.tzinfo is None:\n",
    "            end = end.tz_localize('UTC')\n",
    "        else:\n",
    "            end = end.tz_convert('UTC')\n",
    "\n",
    "        if subdir_min <= end and subdir_max >= start:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Map subdirectories to subjects based on time range overlap\n",
    "subdir_to_subject = {}\n",
    "for subdir, (subdir_min, subdir_max) in subdir_time_ranges.items():\n",
    "    matching_subjects = [\n",
    "        subject for subject, group in subject_activities\n",
    "        if intervals_overlap(subdir_min, subdir_max, list(zip(group['Started'], group['Finished'])))\n",
    "    ]\n",
    "    if len(matching_subjects) == 1:\n",
    "        subdir_to_subject[subdir] = matching_subjects[0]\n",
    "    else:\n",
    "        print(f\"Warning: Subdirectory {subdir} matches {len(matching_subjects)} subjects.\")\n",
    "\n",
    "print(f\"Mapped {len(subdir_to_subject)} subdirectories to subjects.\")\n",
    "\n",
    "# Step 3: Load and Label Accelerometer Data\n",
    "all_labeled_data = []\n",
    "for subdir, subject in subdir_to_subject.items():\n",
    "    csv_files = [f for f in os.listdir(os.path.join(data_dir, subdir)) if f.endswith('.csv')]\n",
    "    data_list = []\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(data_dir, subdir, csv_file)\n",
    "        # Assuming columns: random (0), timestamp (1), x (2), y (3), z (4)\n",
    "        df = pd.read_csv(file_path, usecols=[1, 2, 3, 4], header=None)\n",
    "        df.columns = ['Timestamp', 'x', 'y', 'z']\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        data_list.append(df)\n",
    "    subdir_data = pd.concat(data_list, ignore_index=True)\n",
    "    subdir_data['Subject'] = subject\n",
    "    \n",
    "    # Label data points with activity labels\n",
    "    activities = subject_activities.get_group(subject)\n",
    "    for _, activity in activities.iterrows():\n",
    "        start = activity['Started']\n",
    "        end = activity['Finished']\n",
    "        activity_label = activity['Activity_Label']\n",
    "        mask = (subdir_data['Timestamp'] >= start) & (subdir_data['Timestamp'] <= end)\n",
    "        subdir_data.loc[mask, 'Activity'] = activity_label\n",
    "    \n",
    "    # Keep only labeled data\n",
    "    labeled_data = subdir_data.dropna(subset=['Activity'])\n",
    "    all_labeled_data.append(labeled_data)\n",
    "    print(f\"Processed data for subject {subject} from subdirectory {subdir}.\")\n",
    "\n",
    "all_data = pd.concat(all_labeled_data, ignore_index=True)\n",
    "print(f\"Total labeled data points: {len(all_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037d7924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2812': 'U7'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdir_to_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ec41ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting data into windows...\n",
      "Training windows: 0, Validation windows: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining windows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_windows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Validation windows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_windows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Step 5: Build and Train the CNN Model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m model = \u001b[43mSequential\u001b[49m([\n\u001b[32m     36\u001b[39m     Conv1D(\u001b[32m32\u001b[39m, kernel_size=\u001b[32m5\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, input_shape=(window_size, \u001b[32m3\u001b[39m)),\n\u001b[32m     37\u001b[39m     MaxPooling1D(pool_size=\u001b[32m2\u001b[39m),\n\u001b[32m     38\u001b[39m     Conv1D(\u001b[32m64\u001b[39m, kernel_size=\u001b[32m5\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     39\u001b[39m     MaxPooling1D(pool_size=\u001b[32m2\u001b[39m),\n\u001b[32m     40\u001b[39m     Flatten(),\n\u001b[32m     41\u001b[39m     Dense(\u001b[32m128\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     42\u001b[39m     Dropout(\u001b[32m0.5\u001b[39m),\n\u001b[32m     43\u001b[39m     Dense(\u001b[32m10\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     44\u001b[39m ])\n\u001b[32m     46\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     47\u001b[39m model.summary()\n",
      "\u001b[31mNameError\u001b[39m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 4: Segment Data into Windows\n",
    "def segment_into_windows(df, window_size, stride):\n",
    "    \"\"\"Segment data into fixed-size windows with specified stride.\"\"\"\n",
    "    df = df.sort_values(by=['Subject', 'Timestamp'])\n",
    "    df['activity_change'] = df['Activity'].ne(df['Activity'].shift()).cumsum()\n",
    "    grouped = df.groupby(['Subject', 'activity_change'])\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for _, group in grouped:\n",
    "        group = group.sort_values('Timestamp')\n",
    "        num_samples = len(group)\n",
    "        for start in range(0, num_samples - window_size + 1, stride):\n",
    "            end = start + window_size\n",
    "            window = group.iloc[start:end]\n",
    "            if len(window) == window_size:\n",
    "                windows.append(window[['x', 'y', 'z']].values)\n",
    "                labels.append(window['Activity'].iloc[0] - 1)  # Adjust to 0-based indexing\n",
    "    return np.array(windows), np.array(labels)\n",
    "\n",
    "# Define training and validation subjects\n",
    "train_subjects = ['U1', 'U2', 'U3', 'U4', 'U5', 'U6', 'U7']\n",
    "val_subjects = ['U21', 'U22']\n",
    "\n",
    "train_data = all_data[all_data['Subject'].isin(train_subjects)]\n",
    "val_data = all_data[all_data['Subject'].isin(val_subjects)]\n",
    "\n",
    "window_size = 100  # e.g., 2 seconds at 50Hz\n",
    "stride = 50       # e.g., 1-second overlap\n",
    "print(\"Segmenting data into windows...\")\n",
    "train_windows, train_labels = segment_into_windows(train_data, window_size, stride)\n",
    "val_windows, val_labels = segment_into_windows(val_data, window_size, stride)\n",
    "print(f\"Training windows: {len(train_windows)}, Validation windows: {len(val_windows)}\")\n",
    "\n",
    "# Step 5: Build and Train the CNN Model\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=5, activation='relu', input_shape=(window_size, 3)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"Training the model...\")\n",
    "model.fit(\n",
    "    train_windows, train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_windows, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63df78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
