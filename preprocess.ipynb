{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97ef0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing activity labels...\n",
      "Found activities for 9 subjects.\n",
      "Found 18 subdirectories with accelerometer data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Step 1: Load and Parse Activity Labels\n",
    "print(\"Loading and parsing activity labels...\")\n",
    "activities_df = pd.read_csv(r'C:\\projs\\tmc\\TrainingDataPD25\\TrainingDataPD25\\TrainActivities.csv')\n",
    "activities_df['Started'] = pd.to_datetime(activities_df['Started'], format='mixed', dayfirst=True)\n",
    "activities_df['Finished'] = pd.to_datetime(activities_df['Finished'], format='mixed', dayfirst=True)\n",
    "activities_df['Activity_Label'] = activities_df['Activity Type'].str.extract(r'^(\\d+)').astype(int)\n",
    "\n",
    "# Group activities by subject\n",
    "subject_activities = activities_df.groupby('Subject')\n",
    "print(f\"Found activities for {len(subject_activities)} subjects.\")\n",
    "\n",
    "# Step 2: Map Subdirectories to Subjects\n",
    "data_dir = r'C:\\projs\\tmc\\TrainingDataPD25\\TrainingDataPD25\\users_timeXYZ\\users'\n",
    "subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "print(f\"Found {len(subdirs)} subdirectories with accelerometer data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_range(subdir):\n",
    "    \"\"\"Get the min and max timestamps from all CSV files in a subdirectory.\"\"\"\n",
    "    csv_files = [f for f in os.listdir(os.path.join(data_dir, subdir)) if f.endswith('.csv')]\n",
    "    \n",
    "    min_ts, max_ts = None, None\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(data_dir, subdir, csv_file)\n",
    "        # Assuming timestamp is the second column (index 1)\n",
    "        df = pd.read_csv(file_path, usecols=[1], header=None)\n",
    "        df.columns = ['Timestamp']\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed', dayfirst=True)\n",
    "\n",
    "        current_min = df['Timestamp'].min()\n",
    "        current_max = df['Timestamp'].max()\n",
    "        min_ts = current_min if min_ts is None or current_min < min_ts else min_ts\n",
    "        max_ts = current_max if max_ts is None or current_max > max_ts else max_ts\n",
    "    return min_ts, max_ts\n",
    "\n",
    "# Compute time ranges for each subdirectory\n",
    "subdir_time_ranges = {subdir: get_time_range(subdir) for subdir in subdirs}\n",
    "\n",
    "def intervals_overlap(subdir_min, subdir_max, intervals):\n",
    "    \"\"\"Check if subdirectory time range overlaps with any activity interval.\"\"\"\n",
    "    for start, end in intervals:\n",
    "        if subdir_min <= end and subdir_max >= start:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Map subdirectories to subjects based on time range overlap\n",
    "subdir_to_subject = {}\n",
    "for subdir, (subdir_min, subdir_max) in subdir_time_ranges.items():\n",
    "    matching_subjects = [\n",
    "        subject for subject, group in subject_activities\n",
    "        if intervals_overlap(subdir_min, subdir_max, list(zip(group['Started'], group['Finished'])))\n",
    "    ]\n",
    "    if len(matching_subjects) == 1:\n",
    "        subdir_to_subject[subdir] = matching_subjects[0]\n",
    "    else:\n",
    "        print(f\"Warning: Subdirectory {subdir} matches {len(matching_subjects)} subjects.\")\n",
    "print(f\"Mapped {len(subdir_to_subject)} subdirectories to subjects.\")\n",
    "\n",
    "# Step 3: Load and Label Accelerometer Data\n",
    "all_labeled_data = []\n",
    "for subdir, subject in subdir_to_subject.items():\n",
    "    csv_files = [f for f in os.listdir(os.path.join(data_dir, subdir)) if f.endswith('.csv')]\n",
    "    data_list = []\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(data_dir, subdir, csv_file)\n",
    "        # Assuming columns: random (0), timestamp (1), x (2), y (3), z (4)\n",
    "        df = pd.read_csv(file_path, usecols=[1, 2, 3, 4], header=None)\n",
    "        df.columns = ['Timestamp', 'x', 'y', 'z']\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        data_list.append(df)\n",
    "    subdir_data = pd.concat(data_list, ignore_index=True)\n",
    "    subdir_data['Subject'] = subject\n",
    "    \n",
    "    # Label data points with activity labels\n",
    "    activities = subject_activities.get_group(subject)\n",
    "    for _, activity in activities.iterrows():\n",
    "        start = activity['Started']\n",
    "        end = activity['Finished']\n",
    "        activity_label = activity['Activity_Label']\n",
    "        mask = (subdir_data['Timestamp'] >= start) & (subdir_data['Timestamp'] <= end)\n",
    "        subdir_data.loc[mask, 'Activity'] = activity_label\n",
    "    \n",
    "    # Keep only labeled data\n",
    "    labeled_data = subdir_data.dropna(subset=['Activity'])\n",
    "    all_labeled_data.append(labeled_data)\n",
    "    print(f\"Processed data for subject {subject} from subdirectory {subdir}.\")\n",
    "\n",
    "all_data = pd.concat(all_labeled_data, ignore_index=True)\n",
    "print(f\"Total labeled data points: {len(all_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Segment Data into Windows\n",
    "def segment_into_windows(df, window_size, stride):\n",
    "    \"\"\"Segment data into fixed-size windows with specified stride.\"\"\"\n",
    "    df = df.sort_values(by=['Subject', 'Timestamp'])\n",
    "    df['activity_change'] = df['Activity'].ne(df['Activity'].shift()).cumsum()\n",
    "    grouped = df.groupby(['Subject', 'activity_change'])\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for _, group in grouped:\n",
    "        group = group.sort_values('Timestamp')\n",
    "        num_samples = len(group)\n",
    "        for start in range(0, num_samples - window_size + 1, stride):\n",
    "            end = start + window_size\n",
    "            window = group.iloc[start:end]\n",
    "            if len(window) == window_size:\n",
    "                windows.append(window[['x', 'y', 'z']].values)\n",
    "                labels.append(window['Activity'].iloc[0] - 1)  # Adjust to 0-based indexing\n",
    "    return np.array(windows), np.array(labels)\n",
    "\n",
    "# Define training and validation subjects\n",
    "train_subjects = ['U1', 'U2', 'U3', 'U4', 'U5', 'U6', 'U7']\n",
    "val_subjects = ['U21', 'U22']\n",
    "\n",
    "train_data = all_data[all_data['Subject'].isin(train_subjects)]\n",
    "val_data = all_data[all_data['Subject'].isin(val_subjects)]\n",
    "\n",
    "window_size = 100  # e.g., 2 seconds at 50Hz\n",
    "stride = 50       # e.g., 1-second overlap\n",
    "print(\"Segmenting data into windows...\")\n",
    "train_windows, train_labels = segment_into_windows(train_data, window_size, stride)\n",
    "val_windows, val_labels = segment_into_windows(val_data, window_size, stride)\n",
    "print(f\"Training windows: {len(train_windows)}, Validation windows: {len(val_windows)}\")\n",
    "\n",
    "# Step 5: Build and Train the CNN Model\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=5, activation='relu', input_shape=(window_size, 3)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"Training the model...\")\n",
    "model.fit(\n",
    "    train_windows, train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_windows, val_labels),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
