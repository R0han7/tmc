{
    "trial": 0,
    "fold": 5,
    "epoch": 9,
    "val_acc": 0.42105263157894735,
    "val_f1": 0.30531858492384806,
    "per_class_f1": {
        "10 Slow walk (SHAKING hands/body, tiny step, head forward)": 0.25,
        "2 (FACING camera) both hands SHAKING (sitting position)": 0.46153846153846156,
        "3 Stand up from chair - both hands with SHAKING": 0.0,
        "4 (Sideway) Sit & stand": 0.8571428571428571,
        "5 (Sideway) both hands SHAKING (sitting)": 0.42857142857142855,
        "6 (Sideway) STAND up with - both hands SHAKING": 0.625,
        "7 Cool down - sitting/relax": 0.6666666666666666,
        "8 Walk (LEFT --> Right --> Left)": 0.0,
        "9 Walk & STOP/frozen, full body shaking, rotate then return back": 0.0
    },
    "hyperparameters": {
        "d_model": 256,
        "num_heads": 8,
        "num_layers": 1,
        "dropout": 0.22916070493826265,
        "embedding_dim": 64,
        "learning_rate": 0.002972515581042874,
        "batch_size": 8
    },
    "num_parameters": 438922,
    "model_architecture": "ActivityTransformer(\n  (subject_embedding): Embedding(10, 64)\n  (input_proj): Linear(in_features=103, out_features=256, bias=True)\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.22916070493826265, inplace=False)\n        (linear2): Linear(in_features=256, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.22916070493826265, inplace=False)\n        (dropout2): Dropout(p=0.22916070493826265, inplace=False)\n      )\n    )\n  )\n  (classifier): Linear(in_features=256, out_features=10, bias=True)\n)"
}